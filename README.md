This project, 'Hierarchical Adaptive Transformer,' introduces an innovative approach to efficient transformer computation. It employs a two-level hierarchy for adaptive processing: Exit Gates strategically decide when tokens cease computation, while MoE-style Routers at each layer determine which active tokens undergo Feed-Forward Network (FFN) processing. A key innovation is capacity-constrained routing, enabling top-k selection for precise compute budgets with minimal overhead (0.05% additional parameters). This single-phase training framework aims to optimize efficiency without sacrificing accuracy, achieving notable speedups. The architecture provides fine-grained control over computation, making it suitable for resource-constrained environments.